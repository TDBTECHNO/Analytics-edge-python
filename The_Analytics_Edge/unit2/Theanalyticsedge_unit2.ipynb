{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''In this unit we will discuss about linear regression and using this model we will predict the quality of wine and in recitation, we will discuss \n",
    "about the movie named MoneyBall, using statistics and analytics a team of baseball named Oakland A won a championship'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Linear Regression is a very powerful method to analyze and make predictions and apply it. '''\n",
    "'''Boredeaux wine'''\n",
    "    '''Large differences in price and quality between years, although wine is produced in a similar way'''\n",
    "    '''Meant to be aged, so hard to tell if wine will be good when it is on the market'''\n",
    "    '''Expert tasters predict which ones will be good'''\n",
    "    '''Can analysis be used to come up with a different system for judging wine'''\n",
    "'''Building a model'''\n",
    "    '''Scientist used a method called linear regression'''\n",
    "        '''Predicts an outcome variable, or dependent variable'''\n",
    "        '''predicts using a set of independent variable'''\n",
    "    '''Dependent variable:->Typical price in 1990-1991 wine auctions'''\n",
    "    '''Independent Variable:->'''\n",
    "        '''Age'''\n",
    "        '''Weather'''\n",
    "            '''AVerage growing Season Temperature'''\n",
    "            '''Harvest rain'''\n",
    "            '''Winter Rain'''\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''One Variable Linear Regression'''\n",
    "    '''The goal of linear regression is to create a predictive line through the data. There are many different lines \n",
    "    that could be drawn to predict wine price using average gross season temperature.'''\n",
    "    '''y^i=B0+B1x^i+E^i'''\n",
    "        '''y^i->dependent Variable(wine price) for the ith observation'''\n",
    "        '''x^i->independent variable(temperature) for the ith observation'''\n",
    "        '''E^i->error term for ith observation'''\n",
    "        '''B0->intercept coefficient'''\n",
    "        '''B1->regression coefficient'''\n",
    "    '''The best model has the smallest error terms'''\n",
    "    '''Sum of Squared errors'''\n",
    "        '''SSE hard to interept'''\n",
    "            '''Depends on N'''\n",
    "            '''units are hard to understand'''\n",
    "        '''ROOT_MEAN_SQUARE ERROR(RMSE)'''\n",
    "            '''RMSE=(SSE/N)^1/2'''\n",
    "        '''Normalized by N, Units of dependent Variable'''\n",
    "    '''R-SQUARE'''\n",
    "        '''Compare the best model to the best line model'''\n",
    "        '''The baseline model does not use any variables'''\n",
    "        '''Predicts same outcome(Price) regardless of the independent variable(temperature)'''\n",
    "        \n",
    "'''SSE->Sum of squared error of predicted line\n",
    "SST->sum of squared error of base line\n",
    "'''    \n",
    "'''R^2=1-(SSE/SST)'''\n",
    "'''Interpreting R-SQUARE'''\n",
    "    '''R-SQUARE captures value added from using a model'''\n",
    "        '''R-SQUARE=0:means no improvement over base line'''\n",
    "        '''R-SQUARE=1:means a perfect predictive model'''\n",
    "    '''unitless and universally interpretable'''\n",
    "        '''can still be hard to compare between problems'''\n",
    "        '''good models for easy problems will have R-SQUARE equivalent to 1'''\n",
    "        '''good models for hard problems will have R-SQUARE equivalent to 0'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-1-dbd3a2816808>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-dbd3a2816808>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    '''So far we have only used the Average Growing Season Temperature to predict wine prices'''\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "'''Multivariate Linear Regression'''\n",
    "    '''So far we have only used the Average Growing Season Temperature to predict wine prices'''\n",
    "    '''Many different independent variables ould be used'''\n",
    "        '''AVerage growing season temperature'''\n",
    "        '''harvest rain'''\n",
    "        '''winter rain'''\n",
    "        '''age of wine'''\n",
    "        '''population of france'''\n",
    "    '''using each variable on its own and having different R-SQUARE'''\n",
    "    '''Multiple Linear Regression allows us to use all of these variables to improve our predictive ability'''\n",
    "    '''Adding more variables can improve the model'''\n",
    "    '''Not all available variables should be used'''\n",
    "        '''Each new variable requires more data'''\n",
    "        '''causes overfitting:High R-SQUARE on data used to create model, but bad performance on unsenn data'''\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25 entries, 0 to 24\n",
      "Data columns (total 7 columns):\n",
      "Year           25 non-null int64\n",
      "Price          25 non-null float64\n",
      "WinterRain     25 non-null int64\n",
      "AGST           25 non-null float64\n",
      "HarvestRain    25 non-null int64\n",
      "Age            25 non-null int64\n",
      "FrancePop      25 non-null float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 1.4 KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Price</th>\n",
       "      <th>WinterRain</th>\n",
       "      <th>AGST</th>\n",
       "      <th>HarvestRain</th>\n",
       "      <th>Age</th>\n",
       "      <th>FrancePop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Year</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.447768</td>\n",
       "      <td>0.016970</td>\n",
       "      <td>-0.246916</td>\n",
       "      <td>0.028009</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.994485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Price</th>\n",
       "      <td>-0.447768</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.136651</td>\n",
       "      <td>0.659563</td>\n",
       "      <td>-0.563322</td>\n",
       "      <td>0.447768</td>\n",
       "      <td>-0.466862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>WinterRain</th>\n",
       "      <td>0.016970</td>\n",
       "      <td>0.136651</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.321091</td>\n",
       "      <td>-0.275441</td>\n",
       "      <td>-0.016970</td>\n",
       "      <td>-0.001622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AGST</th>\n",
       "      <td>-0.246916</td>\n",
       "      <td>0.659563</td>\n",
       "      <td>-0.321091</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.064496</td>\n",
       "      <td>0.246916</td>\n",
       "      <td>-0.259162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HarvestRain</th>\n",
       "      <td>0.028009</td>\n",
       "      <td>-0.563322</td>\n",
       "      <td>-0.275441</td>\n",
       "      <td>-0.064496</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.028009</td>\n",
       "      <td>0.041264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Age</th>\n",
       "      <td>-1.000000</td>\n",
       "      <td>0.447768</td>\n",
       "      <td>-0.016970</td>\n",
       "      <td>0.246916</td>\n",
       "      <td>-0.028009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.994485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>FrancePop</th>\n",
       "      <td>0.994485</td>\n",
       "      <td>-0.466862</td>\n",
       "      <td>-0.001622</td>\n",
       "      <td>-0.259162</td>\n",
       "      <td>0.041264</td>\n",
       "      <td>-0.994485</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Year     Price  WinterRain      AGST  HarvestRain       Age  \\\n",
       "Year         1.000000 -0.447768    0.016970 -0.246916     0.028009 -1.000000   \n",
       "Price       -0.447768  1.000000    0.136651  0.659563    -0.563322  0.447768   \n",
       "WinterRain   0.016970  0.136651    1.000000 -0.321091    -0.275441 -0.016970   \n",
       "AGST        -0.246916  0.659563   -0.321091  1.000000    -0.064496  0.246916   \n",
       "HarvestRain  0.028009 -0.563322   -0.275441 -0.064496     1.000000 -0.028009   \n",
       "Age         -1.000000  0.447768   -0.016970  0.246916    -0.028009  1.000000   \n",
       "FrancePop    0.994485 -0.466862   -0.001622 -0.259162     0.041264 -0.994485   \n",
       "\n",
       "             FrancePop  \n",
       "Year          0.994485  \n",
       "Price        -0.466862  \n",
       "WinterRain   -0.001622  \n",
       "AGST         -0.259162  \n",
       "HarvestRain   0.041264  \n",
       "Age          -0.994485  \n",
       "FrancePop     1.000000  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import statistics\n",
    "import statsmodels.formula.api as sm\n",
    "train=pd.read_csv('./wine.csv')#reading a data set\n",
    "train.info()#structure of data set\n",
    "train.describe()#summary of data set\n",
    "result=sm.ols(formula=\"Price ~ AGST\",data=train).fit()#linear regression function using statsmodels using price as dependent variable and AGST as independent variable\n",
    "result.summary()\n",
    "#Lets see our summary'''\n",
    "#The estimate column gives estimate of beta values for our model, B0 is -3.4 and B1 is 0.63'''\n",
    "#R-SQUARE is 0.435'''\n",
    "    #'''Adjusted R-Square is 0.410'''\n",
    "    #'''Multiple R-SQUARE always increase if you add more independent variables, but adjusted R-SQUARE will decrease if you add up an independent variable'\n",
    "result.fittedvalues#estimated or predictive values\n",
    "result.resid#calculating the residuals3\n",
    "SSE=sum(result.resid**2)#calculating the SUm of Squared Errors\n",
    "result1=sm.ols(formula=\"Price ~ AGST+HarvestRain\",data=train).fit()#linear regression function using statmodels using price as dependent variable and AGST+HArvestRain as independent variable\n",
    "result1.summary()\n",
    "SSE2=sum(result1.resid**2)#better than forst model i.e 2.97\n",
    "result3=sm.ols(formula=\"Price ~ AGST+HarvestRain+WinterRain+Age+FrancePop\",data=train).fit()#linear regression function using statsmodel using Price as dependent variable and all other variables as independent variable\n",
    "result3.summary()#as you can see the adjusted and multiple R-SQUARED has been increased\n",
    "SSE3=sum(result3.resid**2)#better than previous results\n",
    "result3.summary()#the independent variables are listed on the second table of the output i.e HarvestRain, AGST etc.Column next to it shows the coefficient of the intercept and each for the independent variables in our model\n",
    "#The remaining columns shows if a variable should be included in the model or if its coefficient is significantly different from 0\n",
    "#A coefficient of 0 means the vaue doesn't change our prediction .\n",
    "#the std. error column gives a measure of how much the coefficients is likely to vary from the estimated value\n",
    "#The t-value is the estimate divided by the standard error, it will be negative if the estimate is negative and positive for positive. The larger is the absolute value of t, more likely coefficient is to be significant\n",
    "#the last column of numbers gives how plausible it is that coefficient is actually 0, less plausible means less probability. We want independent variables with small values in this column\n",
    "#***->0 prob. value\n",
    "#**->between 0.001 and 0.01 prob. value\n",
    "#*->between 0.01 and 0.05 prob. value\n",
    "#. ->between 0.05 and 0.10\n",
    "# Except for these range variables, they are not significant and not useful for our model\n",
    "#As you can see AGe and FrancePop are insignificant for our model\n",
    "result4=sm.ols(formula=\"Price ~ AGST+HarvestRain+WinterRain+Age\",data=train).fit()\n",
    "result4.summary()#as you can see the values of adjusted R-Square has been increased so it is strong as compared to previous model\n",
    "#but you also can see, in this new model or say result, Age has become significant. This is because of multicollinearity.Age and FrancePop are highly correlated\n",
    "\n",
    "\n",
    "\n",
    "#CORRELATION\n",
    "    #A measure of the linear relationship between variables, like we compute pearson R in statistics\n",
    "        #+1 corresponds to perfect positive linear relationship\n",
    "        #0 corresponds to no linear relationship\n",
    "        #-1 corresponds to perfect negative linear relationship\n",
    "cor1=np.corrcoef(train.WinterRain,train.Price)[0,1]#finding the correlation between winterrain and price\n",
    "cor2=np.corrcoef(train.Age,train.FrancePop)[0,1]#finding the correlation between age and Francepop and as you can see they are highly correlated(negative) \n",
    "cor3=train.corr()#correlation of the whole variables of the given data set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2 entries, 0 to 1\n",
      "Data columns (total 7 columns):\n",
      "Year           2 non-null int64\n",
      "Price          2 non-null float64\n",
      "WinterRain     2 non-null int64\n",
      "AGST           2 non-null float64\n",
      "HarvestRain    2 non-null int64\n",
      "Age            2 non-null int64\n",
      "FrancePop      2 non-null float64\n",
      "dtypes: float64(3), int64(4)\n",
      "memory usage: 184.0 bytes\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.7944277602631964"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Predictive Ability\n",
    "    #Our wine model had a value of R-SQUARE 0.83.\n",
    "    #tells us our accuracy on the data that we used to build the model, often called as training data.\n",
    "    #but what about the new data?, often called as test data.\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "import statistics\n",
    "import os\n",
    "test=pd.read_csv('./wine_test.csv')\n",
    "test.info()#structure of new data set\n",
    "prediction=result4.predict(test)#first data pojnt we predict 6.76 and second for 6.68, we can quantify this calculating the R-SQUARE\n",
    "SSEnew=sum((test.Price-prediction)**2)#sum of squared errors prediction\n",
    "SST=sum((test.Price-statistics.mean(train.Price))**2)#original r square or say baseline model\n",
    "rsquare=1-SSEnew/SST#calculating residuals of new test set and comes out preety good, this is basically the accuracy iof our model\n",
    "#Better model R^2 does not necessarily mean better test set R^2\n",
    "#Need more data to be conclusive\n",
    "#out of sample R^2 can be negative\n",
    "#Two data points in your test set is not good enough to know about the accuracy of oour model\n",
    "#test set R^2 can be negative but not on train set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "'''Story of Moneyball'''\n",
    "        '''Moneyball tells the story of OAKLAND A's in 2002'''\n",
    "        '''One of the poorest teams in baseball'''\n",
    "            '''New ownership and budget cuts in 1995'''\n",
    "        '''But they were improving'''\n",
    "        '''The problem'''\n",
    "            '''Rich teams can afford the all-star players'''\n",
    "            '''How do the poor teams compete'''\n",
    "        '''There were three major teams, NewYork Yankees, RedFox, Oakland A'''\n",
    "            '''NewYork Yankees spent about 90$million and won 100 games'''\n",
    "            '''Red Fox spend around $80million and won about 90 games'''\n",
    "            '''Oakland A's spend around $30million and won about 90 games'''.\n",
    "            '''RedFox and NewYork Yankees can afford all star players'''\n",
    "            '''Oakland A's cant afford the all stars, but they are still make to playoffs. how?'''\n",
    "            '''They take a quantitative approach and find undervalued players'''\n",
    "            '''The Oakland A's is selecting players on their statistics, not their looks'''\n",
    "'''The goal of a baseball team is to make a playoffs'''\n",
    "'''The oakland A's approach was to get playoffs by using analytics'''\n",
    "'''We will use linear regression to oredict how many games a tea will win using the difference between runs scored and runs allowed'''\n",
    "'''We will then use linear regression again to predict the number of runs a team will allow using fielding and pitching statistics'''\n",
    "'''we will start b7 figuring out how many games a team needs to get it to playoffs'''\n",
    "'''If a team won 95 games or more, will likely to made it to playoffs'''\n",
    "'''Winning 95 games'''\n",
    "    '''How does a team win games?'''\n",
    "    '''They score more runs than their opponent'''\n",
    "    '''But how many more?'''\n",
    "    '''The A's calculated that they need to score 135 more runs that they allowed during the regular season to expect to win 95 games'''\n",
    "    '''Let's verify this using linear regression''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1232 entries, 0 to 1231\n",
      "Data columns (total 15 columns):\n",
      "Team            1232 non-null object\n",
      "League          1232 non-null object\n",
      "Year            1232 non-null int64\n",
      "RS              1232 non-null int64\n",
      "RA              1232 non-null int64\n",
      "W               1232 non-null int64\n",
      "OBP             1232 non-null float64\n",
      "SLG             1232 non-null float64\n",
      "BA              1232 non-null float64\n",
      "Playoffs        1232 non-null int64\n",
      "RankSeason      244 non-null float64\n",
      "RankPlayoffs    244 non-null float64\n",
      "G               1232 non-null int64\n",
      "OOBP            420 non-null float64\n",
      "OSLG            420 non-null float64\n",
      "dtypes: float64(7), int64(6), object(2)\n",
      "memory usage: 144.4+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 902 entries, 330 to 1231\n",
      "Data columns (total 15 columns):\n",
      "Team            902 non-null object\n",
      "League          902 non-null object\n",
      "Year            902 non-null int64\n",
      "RS              902 non-null int64\n",
      "RA              902 non-null int64\n",
      "W               902 non-null int64\n",
      "OBP             902 non-null float64\n",
      "SLG             902 non-null float64\n",
      "BA              902 non-null float64\n",
      "Playoffs        902 non-null int64\n",
      "RankSeason      154 non-null float64\n",
      "RankPlayoffs    154 non-null float64\n",
      "G               902 non-null int64\n",
      "OOBP            90 non-null float64\n",
      "OSLG            90 non-null float64\n",
      "dtypes: float64(7), int64(6), object(2)\n",
      "memory usage: 112.8+ KB\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 902 entries, 330 to 1231\n",
      "Data columns (total 16 columns):\n",
      "Team            902 non-null object\n",
      "League          902 non-null object\n",
      "Year            902 non-null int64\n",
      "RS              902 non-null int64\n",
      "RA              902 non-null int64\n",
      "W               902 non-null int64\n",
      "OBP             902 non-null float64\n",
      "SLG             902 non-null float64\n",
      "BA              902 non-null float64\n",
      "Playoffs        902 non-null int64\n",
      "RankSeason      154 non-null float64\n",
      "RankPlayoffs    154 non-null float64\n",
      "G               902 non-null int64\n",
      "OOBP            90 non-null float64\n",
      "OSLG            90 non-null float64\n",
      "RD              902 non-null int64\n",
      "dtypes: float64(7), int64(7), object(2)\n",
      "memory usage: 119.8+ KB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/deepu8489/anaconda2/lib/python2.7/site-packages/ipykernel_launcher.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>W</td>        <th>  R-squared:         </th> <td>   0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.881</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   6651.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>11:31:49</td>     <th>  Log-Likelihood:    </th> <td> -2515.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   902</td>      <th>  AIC:               </th> <td>   5035.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   900</td>      <th>  BIC:               </th> <td>   5045.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   80.8814</td> <td>    0.131</td> <td>  616.675</td> <td> 0.000</td> <td>   80.624</td> <td>   81.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>RD</th>        <td>    0.1058</td> <td>    0.001</td> <td>   81.554</td> <td> 0.000</td> <td>    0.103</td> <td>    0.108</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 5.788</td> <th>  Durbin-Watson:     </th> <td>   2.076</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.055</td> <th>  Jarque-Bera (JB):  </th> <td>   5.736</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td>-0.195</td> <th>  Prob(JB):          </th> <td>  0.0568</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 3.033</td> <th>  Cond. No.          </th> <td>    101.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      W   R-squared:                       0.881\n",
       "Model:                            OLS   Adj. R-squared:                  0.881\n",
       "Method:                 Least Squares   F-statistic:                     6651.\n",
       "Date:                Sun, 24 Mar 2019   Prob (F-statistic):               0.00\n",
       "Time:                        11:31:49   Log-Likelihood:                -2515.5\n",
       "No. Observations:                 902   AIC:                             5035.\n",
       "Df Residuals:                     900   BIC:                             5045.\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     80.8814      0.131    616.675      0.000      80.624      81.139\n",
       "RD             0.1058      0.001     81.554      0.000       0.103       0.108\n",
       "==============================================================================\n",
       "Omnibus:                        5.788   Durbin-Watson:                   2.076\n",
       "Prob(Omnibus):                  0.055   Jarque-Bera (JB):                5.736\n",
       "Skew:                          -0.195   Prob(JB):                       0.0568\n",
       "Kurtosis:                       3.033   Cond. No.                         101.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt \n",
    "import statsmodels.formula.api as sm\n",
    "import statistics\n",
    "train=pd.read_csv('./baseball.csv')#loading a baseball data set\n",
    "train.describe()#summary of the baseball data set\n",
    "train.info()#structure of the baseball data set\n",
    "moneyball=train[train.Year<2002]#we are using the data used by paul depodesta, statistician hired by the owner of oakland A's owner and data was upto the year 2001\n",
    "moneyball.info()\n",
    "#Now we want linear regression equation to predict wins using the difference between the runs scored and runs allowed\n",
    "moneyball['RD']=moneyball.RS-moneyball.RA#we have created a new variable name RD(Run Difference) and it is equal to Run scored and runs allowed\n",
    "moneyball.info()\n",
    "plt.scatter(moneyball.RD,moneyball.W)#as you can see there's a strong linear relationship between Run difference and wins\n",
    "winReg=sm.ols(formula=\"W ~ RD\",data=moneyball).fit()#check the mathematically lineaar relationship between run difference and wins\n",
    "winReg.summary()#as you can see the r square value is quite high\n",
    "#as here we can see coefficients are 80.8814 which B0, 0.105766 which is B1. Now how does the statstician calculated the wins required. \n",
    "#Y=B0+B1x\n",
    "#W=80.8814+0.1058(RD)\n",
    "#W>=95\n",
    "#so->   RD>=133.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 902 entries, 330 to 1231\n",
      "Data columns (total 16 columns):\n",
      "Team            902 non-null object\n",
      "League          902 non-null object\n",
      "Year            902 non-null int64\n",
      "RS              902 non-null int64\n",
      "RA              902 non-null int64\n",
      "W               902 non-null int64\n",
      "OBP             902 non-null float64\n",
      "SLG             902 non-null float64\n",
      "BA              902 non-null float64\n",
      "Playoffs        902 non-null int64\n",
      "RankSeason      154 non-null float64\n",
      "RankPlayoffs    154 non-null float64\n",
      "G               902 non-null int64\n",
      "OOBP            90 non-null float64\n",
      "OSLG            90 non-null float64\n",
      "RD              902 non-null int64\n",
      "dtypes: float64(7), int64(7), object(2)\n",
      "memory usage: 119.8+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>RS</td>        <th>  R-squared:         </th> <td>   0.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   5934.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 24 Mar 2019</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>14:19:13</td>     <th>  Log-Likelihood:    </th> <td> -4174.2</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   902</td>      <th>  AIC:               </th> <td>   8354.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   899</td>      <th>  BIC:               </th> <td>   8369.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td> -804.6271</td> <td>   18.921</td> <td>  -42.526</td> <td> 0.000</td> <td> -841.761</td> <td> -767.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>OBP</th>       <td> 2737.7680</td> <td>   90.685</td> <td>   30.190</td> <td> 0.000</td> <td> 2559.790</td> <td> 2915.746</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>SLG</th>       <td> 1584.9086</td> <td>   42.156</td> <td>   37.597</td> <td> 0.000</td> <td> 1502.174</td> <td> 1667.643</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 3.099</td> <th>  Durbin-Watson:     </th> <td>   1.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.212</td> <th>  Jarque-Bera (JB):  </th> <td>   3.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.143</td> <th>  Prob(JB):          </th> <td>   0.212</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.972</td> <th>  Cond. No.          </th> <td>    134.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Warnings:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     RS   R-squared:                       0.930\n",
       "Model:                            OLS   Adj. R-squared:                  0.929\n",
       "Method:                 Least Squares   F-statistic:                     5934.\n",
       "Date:                Sun, 24 Mar 2019   Prob (F-statistic):               0.00\n",
       "Time:                        14:19:13   Log-Likelihood:                -4174.2\n",
       "No. Observations:                 902   AIC:                             8354.\n",
       "Df Residuals:                     899   BIC:                             8369.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept   -804.6271     18.921    -42.526      0.000    -841.761    -767.493\n",
       "OBP         2737.7680     90.685     30.190      0.000    2559.790    2915.746\n",
       "SLG         1584.9086     42.156     37.597      0.000    1502.174    1667.643\n",
       "==============================================================================\n",
       "Omnibus:                        3.099   Durbin-Watson:                   1.933\n",
       "Prob(Omnibus):                  0.212   Jarque-Bera (JB):                3.106\n",
       "Skew:                           0.143   Prob(JB):                        0.212\n",
       "Kurtosis:                       2.972   Cond. No.                         134.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Scoring Runs\n",
    "    #How does a team score more runs?\n",
    "    #The A's discovered the two baseball statistics were significantly more important than anything else\n",
    "        #On-Base Percentage(OBP)\n",
    "            #Percentage of time a player gets on base(including walks)\n",
    "        #Slugging Percentage(SLG)\n",
    "            #How far a player gets around the bases on his turn(measures power)\n",
    "    #Most teams focused on Batting Average(BA)\n",
    "        #getting on base by hitting the ball\n",
    "    #The A's claimed that:\n",
    "        #OBP was most important\n",
    "        #SLG was important\n",
    "        #BA was overvalued\n",
    "    #Can we use linear regression to verify which baseball stats are more important to predict runs?\n",
    "import pandas as pd\n",
    "import statistics\n",
    "import statsmodels.formula.api as sm\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "moneyball.info()\n",
    "runsReg=sm.ols(formula=\"RS ~  OBP+SLG+BA\",data=moneyball).fit()#we wish to see if the runs scored is directly connected to onbase percentage, slugging percenatge and batting average\n",
    "runsReg.summary()#as you can see the RSQuare is quite high of this model and all our variables are significannt, and our coefficents are negative, that means a team with lower batting average will score more runs\n",
    "#and these three statistics are highly correlated, let's see by removing batting average\n",
    "runsReg=sm.ols(formula=\"RS ~ OBP+SLG\",data=moneyball).fit()\n",
    "runsReg.summary()#we can see, our variables are still significant and RSQUARE is still high\n",
    "#BY THIS WE CANY VERIFY THAT BATTING PERCENTAGE IS OVERVALUED\n",
    "\n",
    "#using our regression model we would like to predict before the season starts, how many games the 2002 oakland A's will win\n",
    "#The models for runs use team statistics\n",
    "#how many runs team will score, how many runs they will allow, as these modelmuse statistics\n",
    "#we can't predict the actual score but using statistics we can estimate thi thing using past players data\n",
    "#this approach assumes that past performance has been related to future performance. We can estimate 2002 performace by going through 2001 perfromance\\\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''WELCOME TO RECITATION, IN THIS WE WILL DISCUSS ABOUT AN NBA(NATIONAL BASKETBALL ASSOCIATION) DATASET'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<unknown>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<unknown>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    2 PA\u001b[0m\n\u001b[0m       ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statistics\n",
    "import statsmodels.formula.api as sm\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "train=pd.read_csv('./NBA_train.csv')\n",
    "train.head()#first 5 rows of the given NBA data\n",
    "a=plt.scatter(train.W,train.Playoffs)#relation finding by a plot and as you can see  number of more wins, as number of more playoffs\n",
    "pd.crosstab(train.W.dropna(),train.Playoffs.dropna())#same thing we did by creating a table of these two variables\n",
    "#can we use the difference between points scored and points allowed throughout regular season in order to predict the number of games that a team will win?\n",
    "train['ptsdiff']=train.PTS-train.oppPTS\n",
    "plt.scatter(train.W,train.ptsdiff)#as we can see there is a positive strong linear relationshio between these two variables\n",
    "result=sm.ols(formula=\"W ~ ptsdiff\",data=train).fit()#lets see thesee relation by a linear regression model and predict the values\n",
    "result.summary()# as you can see the Rsquare value ishigh and shows a positive linear relation ship between these two variables\n",
    "# we will build an equation to predict points scored using some basketbball statistics, so points willbe now dependent variable\n",
    "res=sm.ols(formula=\"PTS ~ 2PA+3PA+FTA+AST+ORB+DRB+TOV+STL+BLK\",data=train).fit()\n",
    "res.summary()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SeasonEnd</th>\n",
       "      <th>Playoffs</th>\n",
       "      <th>W</th>\n",
       "      <th>PTS</th>\n",
       "      <th>oppPTS</th>\n",
       "      <th>FG</th>\n",
       "      <th>FGA</th>\n",
       "      <th>2P</th>\n",
       "      <th>2PA</th>\n",
       "      <th>3P</th>\n",
       "      <th>3PA</th>\n",
       "      <th>FT</th>\n",
       "      <th>FTA</th>\n",
       "      <th>ORB</th>\n",
       "      <th>DRB</th>\n",
       "      <th>AST</th>\n",
       "      <th>STL</th>\n",
       "      <th>BLK</th>\n",
       "      <th>TOV</th>\n",
       "      <th>ptsdiff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "      <td>835.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1996.319760</td>\n",
       "      <td>0.574850</td>\n",
       "      <td>41.000000</td>\n",
       "      <td>8370.239521</td>\n",
       "      <td>8370.239521</td>\n",
       "      <td>3200.367665</td>\n",
       "      <td>6873.318563</td>\n",
       "      <td>2881.324551</td>\n",
       "      <td>5956.444311</td>\n",
       "      <td>319.043114</td>\n",
       "      <td>916.874251</td>\n",
       "      <td>1650.461078</td>\n",
       "      <td>2189.953293</td>\n",
       "      <td>1061.584431</td>\n",
       "      <td>2427.354491</td>\n",
       "      <td>1912.112575</td>\n",
       "      <td>668.364072</td>\n",
       "      <td>419.805988</td>\n",
       "      <td>1302.837126</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.243808</td>\n",
       "      <td>0.494662</td>\n",
       "      <td>12.740822</td>\n",
       "      <td>581.040114</td>\n",
       "      <td>587.543959</td>\n",
       "      <td>287.181266</td>\n",
       "      <td>401.027166</td>\n",
       "      <td>446.097941</td>\n",
       "      <td>830.596327</td>\n",
       "      <td>199.698941</td>\n",
       "      <td>523.982964</td>\n",
       "      <td>197.651728</td>\n",
       "      <td>244.491086</td>\n",
       "      <td>150.224519</td>\n",
       "      <td>130.671523</td>\n",
       "      <td>221.610925</td>\n",
       "      <td>93.393044</td>\n",
       "      <td>82.274913</td>\n",
       "      <td>153.973470</td>\n",
       "      <td>379.547673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>6901.000000</td>\n",
       "      <td>6909.000000</td>\n",
       "      <td>2565.000000</td>\n",
       "      <td>5972.000000</td>\n",
       "      <td>1981.000000</td>\n",
       "      <td>4153.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>75.000000</td>\n",
       "      <td>1189.000000</td>\n",
       "      <td>1475.000000</td>\n",
       "      <td>639.000000</td>\n",
       "      <td>2044.000000</td>\n",
       "      <td>1423.000000</td>\n",
       "      <td>455.000000</td>\n",
       "      <td>204.000000</td>\n",
       "      <td>931.000000</td>\n",
       "      <td>-1246.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1989.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>31.000000</td>\n",
       "      <td>7934.000000</td>\n",
       "      <td>7934.000000</td>\n",
       "      <td>2974.000000</td>\n",
       "      <td>6563.500000</td>\n",
       "      <td>2510.000000</td>\n",
       "      <td>5269.000000</td>\n",
       "      <td>131.500000</td>\n",
       "      <td>413.000000</td>\n",
       "      <td>1502.500000</td>\n",
       "      <td>2008.000000</td>\n",
       "      <td>953.500000</td>\n",
       "      <td>2346.500000</td>\n",
       "      <td>1735.000000</td>\n",
       "      <td>599.000000</td>\n",
       "      <td>359.000000</td>\n",
       "      <td>1192.000000</td>\n",
       "      <td>-268.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1996.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>42.000000</td>\n",
       "      <td>8312.000000</td>\n",
       "      <td>8365.000000</td>\n",
       "      <td>3150.000000</td>\n",
       "      <td>6831.000000</td>\n",
       "      <td>2718.000000</td>\n",
       "      <td>5706.000000</td>\n",
       "      <td>329.000000</td>\n",
       "      <td>942.000000</td>\n",
       "      <td>1628.000000</td>\n",
       "      <td>2176.000000</td>\n",
       "      <td>1055.000000</td>\n",
       "      <td>2433.000000</td>\n",
       "      <td>1899.000000</td>\n",
       "      <td>658.000000</td>\n",
       "      <td>410.000000</td>\n",
       "      <td>1289.000000</td>\n",
       "      <td>21.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2005.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>50.500000</td>\n",
       "      <td>8784.500000</td>\n",
       "      <td>8768.500000</td>\n",
       "      <td>3434.500000</td>\n",
       "      <td>7157.000000</td>\n",
       "      <td>3296.000000</td>\n",
       "      <td>6753.500000</td>\n",
       "      <td>481.500000</td>\n",
       "      <td>1347.500000</td>\n",
       "      <td>1781.000000</td>\n",
       "      <td>2352.000000</td>\n",
       "      <td>1167.000000</td>\n",
       "      <td>2516.500000</td>\n",
       "      <td>2077.500000</td>\n",
       "      <td>729.000000</td>\n",
       "      <td>469.500000</td>\n",
       "      <td>1395.500000</td>\n",
       "      <td>287.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2011.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>72.000000</td>\n",
       "      <td>10371.000000</td>\n",
       "      <td>10723.000000</td>\n",
       "      <td>3980.000000</td>\n",
       "      <td>8868.000000</td>\n",
       "      <td>3954.000000</td>\n",
       "      <td>7873.000000</td>\n",
       "      <td>841.000000</td>\n",
       "      <td>2284.000000</td>\n",
       "      <td>2388.000000</td>\n",
       "      <td>3051.000000</td>\n",
       "      <td>1520.000000</td>\n",
       "      <td>2753.000000</td>\n",
       "      <td>2575.000000</td>\n",
       "      <td>1053.000000</td>\n",
       "      <td>716.000000</td>\n",
       "      <td>1873.000000</td>\n",
       "      <td>1004.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         SeasonEnd    Playoffs           W           PTS        oppPTS  \\\n",
       "count   835.000000  835.000000  835.000000    835.000000    835.000000   \n",
       "mean   1996.319760    0.574850   41.000000   8370.239521   8370.239521   \n",
       "std       9.243808    0.494662   12.740822    581.040114    587.543959   \n",
       "min    1980.000000    0.000000   11.000000   6901.000000   6909.000000   \n",
       "25%    1989.000000    0.000000   31.000000   7934.000000   7934.000000   \n",
       "50%    1996.000000    1.000000   42.000000   8312.000000   8365.000000   \n",
       "75%    2005.000000    1.000000   50.500000   8784.500000   8768.500000   \n",
       "max    2011.000000    1.000000   72.000000  10371.000000  10723.000000   \n",
       "\n",
       "                FG          FGA           2P          2PA          3P  \\\n",
       "count   835.000000   835.000000   835.000000   835.000000  835.000000   \n",
       "mean   3200.367665  6873.318563  2881.324551  5956.444311  319.043114   \n",
       "std     287.181266   401.027166   446.097941   830.596327  199.698941   \n",
       "min    2565.000000  5972.000000  1981.000000  4153.000000   10.000000   \n",
       "25%    2974.000000  6563.500000  2510.000000  5269.000000  131.500000   \n",
       "50%    3150.000000  6831.000000  2718.000000  5706.000000  329.000000   \n",
       "75%    3434.500000  7157.000000  3296.000000  6753.500000  481.500000   \n",
       "max    3980.000000  8868.000000  3954.000000  7873.000000  841.000000   \n",
       "\n",
       "               3PA           FT          FTA          ORB          DRB  \\\n",
       "count   835.000000   835.000000   835.000000   835.000000   835.000000   \n",
       "mean    916.874251  1650.461078  2189.953293  1061.584431  2427.354491   \n",
       "std     523.982964   197.651728   244.491086   150.224519   130.671523   \n",
       "min      75.000000  1189.000000  1475.000000   639.000000  2044.000000   \n",
       "25%     413.000000  1502.500000  2008.000000   953.500000  2346.500000   \n",
       "50%     942.000000  1628.000000  2176.000000  1055.000000  2433.000000   \n",
       "75%    1347.500000  1781.000000  2352.000000  1167.000000  2516.500000   \n",
       "max    2284.000000  2388.000000  3051.000000  1520.000000  2753.000000   \n",
       "\n",
       "               AST          STL         BLK          TOV      ptsdiff  \n",
       "count   835.000000   835.000000  835.000000   835.000000   835.000000  \n",
       "mean   1912.112575   668.364072  419.805988  1302.837126     0.000000  \n",
       "std     221.610925    93.393044   82.274913   153.973470   379.547673  \n",
       "min    1423.000000   455.000000  204.000000   931.000000 -1246.000000  \n",
       "25%    1735.000000   599.000000  359.000000  1192.000000  -268.000000  \n",
       "50%    1899.000000   658.000000  410.000000  1289.000000    21.000000  \n",
       "75%    2077.500000   729.000000  469.500000  1395.500000   287.500000  \n",
       "max    2575.000000  1053.000000  716.000000  1873.000000  1004.000000  "
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'We will write a linear regression code from scratch'"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''Now we know that we can make some predictions using linear regression and we have estimated its values using statsmodels library, but how does the linear regression actually work?'''\n",
    "'''We will write a linear regression code from scratch'''\n",
    "'''In this problem we have an input variable - X and one output variable - Y. And we want to build linear relationship between these variables. Here the input variable is called Independent Variable and the output variable is called Dependent Variable. We can define this linear relationship as follows:\n",
    "\n",
    "Y = \\beta_0 + \\beta_1XY=β \n",
    "0\n",
    "​\t +β \n",
    "1\n",
    "​\t X\n",
    "The \\beta_1β \n",
    "1\n",
    "​\t  is called a scale factor or coefficient and \\beta_0β \n",
    "0\n",
    "​\t  is called bias coefficient. The bias coeffient gives an extra degree of freedom to this model. This equation is similar to the line equation y = mx + by=mx+b with m = \\beta_1m=β \n",
    "1\n",
    "​\t (Slope) and b = \\beta_0b=β \n",
    "0\n",
    "​\t (Intercept). So in this Simple Linear Regression model we want to draw a line between X and Y which estimates the relationship between X and Y.\n",
    "\n",
    "But how do we find these coefficients? That’s the learning procedure. We can find these using different approaches. One is called Ordinary Least Square Method and other one is called Gradient Descent Approach. We will use Ordinary Least Square Method in Simple Linear Regression and Gradient Descent Approach in Multiple Linear Regression in post.'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12.584627964022893, 4.58789860997547)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-0.7764981133184876"
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Let's create our own data frame and build a linear rwgression model from scratch on it\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df=pd.DataFrame({\"Number_of_hours_spent_driving\":[10,9,2,15,10,16,11,16],\"Risk_on_a_scale_0-100\":[95,80,10,50,45,98,38,93]})\n",
    "X=df[\"Number_of_hours_spent_driving\"].values#independent variable\n",
    "Y=df[\"Risk_on_a_scale_0-100\"].values#dependent variable\n",
    "\n",
    "#Now we will work on getting the coefficients i.e beta 1 abd beta 0\n",
    "#Y=beta0+beta1(X)\n",
    "#beta1=∑ (xi-ˉx)(yi-ˉy)/∑(xi-ˉx)**2\n",
    "#beta0=[ˉy - (beta1)ˉx]\n",
    "#first we will caluate the mean of X and Y\n",
    "xmean=statistics.mean(X)\n",
    "ymean=statistics.mean(Y)\n",
    "m=len(X)\n",
    "numerator=0\n",
    "denominator=0\n",
    "for i in range(m):\n",
    "    numerator+=(X[i]-xmean)*(Y[i]-ymean)\n",
    "    denominator+=(X[i]-xmean)**2\n",
    "beta1=numerator/denominator\n",
    "beta0=ymean-(beta1)*xmean\n",
    "print(beta0,beta1)\n",
    "#Risk_on_a_scale_0-100=12.59+(4.58)Number_of_hours_spent_driving\n",
    "#now you get your regression line equation\n",
    "\n",
    "\n",
    "#LETS PLOT OUR REGRESSION LINE\n",
    "xmax=np.max(X)+100\n",
    "xmin=np.min(X)-100\n",
    "x=np.linspace(xmin,xmax,1000)\n",
    "y=beta0+beta1*x\n",
    "plt.scatter(x,y)\n",
    "#This model is not so bad, but we need to find how good is our model. There are many methods to evaluate models. We will use Root Mean Squared Error and coeffif=cient of Determination(RSquare)\n",
    "#RMSE=(∑((^yi-y)**2)/m)**(1/2)\n",
    "#^yi is the ith predicted output values\n",
    "#Now let's calculate RMSE\n",
    "rmse=0\n",
    "for i in range(0,m):\n",
    "    y_pred=beta0+beta1*X[i]#predicted line equation\n",
    "    rmse+=(Y[i]-y_pred)**2\n",
    "rmse=np.sqrt(rmse/m)\n",
    "#now we will find R**2\n",
    "#SSt is the total sum of squares=∑(yi-ˉy)**2\n",
    "#SSe is the total sum of squared errors=∑(yi-^yi)**2\n",
    "#R**2=1-(SSt/SSe)\n",
    "#RSquare ranges from 0 to 1\n",
    "sst=0\n",
    "sse=0\n",
    "for i in range(0,m):\n",
    "    y_pred=beta0+beta1*(X[i])\n",
    "    sst+=(Y[i]-ymean)**2\n",
    "    sse+=(Y[i]-y_pred)**2\n",
    "Rsquare=1-(sst/sse)\n",
    "Rsquare\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
